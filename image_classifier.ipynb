{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import os\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from keras.callbacks import History\n",
    "from keras.preprocessing import image \n",
    "from keras import backend as K \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Variables\n",
    "#set width and height for resizing the training data\n",
    "img_width, img_height = 224, 224\n",
    "num_classes = 5 #number of classes for this use case (Bauhaus, Expressionismus, Impressionismus, Romantik, Rennaisance)\n",
    "train_data_dir = os.path.abspath(\"multi_epochen_data/train\")\n",
    "validation_data_dir = os.path.abspath(\"multi_epochen_data/test\")\n",
    "nb_train_samples = 3500 #number of train samples\n",
    "nb_validation_samples = 500 #number of test samples\n",
    "epochs = 30\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes sure the input data is recognized with the right shape, as different keras backends use different naming conventions\n",
    "# (some like theano using \"channels_first\", tensorflow using \"channels_last\")\n",
    "# https://www.codesofinterest.com/2017/09/keras-image-data-format.html\n",
    "if K.image_data_format() == 'channels_first': \n",
    "\tinput_shape = (3, img_width, img_height) \n",
    "else: \n",
    "\tinput_shape = (img_width, img_height, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data from pictures\n",
    "# original images consist of RGB coefficients between 0-255. As this is to high for a typical model to process, all the values are rescaled to a value between 0 and 1\n",
    "# define in what ways to alter the image (into new seperate images)\n",
    "\n",
    "train_datagen = ImageDataGenerator( \n",
    "\t\t\t\trescale = 1. / 255, \n",
    "\t\t\t\tshear_range = 0.2, \n",
    "\t\t\t\tzoom_range = 0.2, \n",
    "                horizontal_flip = True,\n",
    "                rotation_range=45,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                ) \n",
    "#just resizing, we do not want to alter the test data in other ways\n",
    "test_datagen = ImageDataGenerator(rescale = 1. / 255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the images and process them\n",
    "# train_datagen is of the ImageDataGenerator class\n",
    "# the arguments it takes should be self explanatory, as the variables that get assigned have all been created above\n",
    "# class_mode = 'categorical' tells the generator that we are working with more than 2 classes (as opposed to class_mode = 'binary')\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, \n",
    "\t\t\t\t\t\t\ttarget_size =(img_width, img_height), \n",
    "\t\t\t\t\tbatch_size = batch_size, class_mode ='categorical') \n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory( \n",
    "\t\t\t\t\t\t\t\t\tvalidation_data_dir, \n",
    "\t\t\t\ttarget_size =(img_width, img_height), \n",
    "\t\tbatch_size = batch_size, class_mode ='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model structure\n",
    "#the code commentary will not go into great detail here\n",
    "#this model has been created through a lot of trial and error\n",
    "#explanations to parts of this model, as needed, can be found in the project report\n",
    "model = Sequential() \n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape = input_shape)) \n",
    "model.add(MaxPooling2D(pool_size =(2, 2))) #reduce size without loosing features\n",
    "model.add(Dropout(0.2)) #reduce overfitting\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten()) # make 1D array out of 2D image\n",
    "model.add(Dense(128, activation='relu')) \n",
    "model.add(Dense(128, activation='relu')) \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "#softmax is used to take the numerics of the last layer and turn them into probabilities, so the output vektor sums up to one\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an optimizer is chosen and given its parameters\n",
    "rms = keras.optimizers.RMSprop(learning_rate = 0.001, rho=0.9)\n",
    "# compile all the defined layers\n",
    "\n",
    "model.compile(loss ='categorical_crossentropy', #categorical crossentropy, as we have more than 2 labels\n",
    "\t\t\t\t\toptimizer =rms, \n",
    "\t\t\t\tmetrics =['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = History()\n",
    "#this is the step where the model that has been defined before is trained\n",
    "model.fit_generator(train_generator,\n",
    "\tsteps_per_epoch = nb_train_samples // batch_size, \n",
    "\tepochs = epochs, validation_data = validation_generator, \n",
    "\tvalidation_steps = nb_validation_samples // batch_size,\n",
    "                   callbacks=[history])\n",
    "\n",
    "model.save_weights('multi_epochen_weights.h5') \n",
    "model.save('multi_epochen.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "# the code below is used to graphically show different performance metrics of the CNN\n",
    "# it is not relevant for the actual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training and validation accuracy per epoch\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training and validation loss per epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    source: https://scikit-learn.org/0.18/auto_examples/model_selection/plot_confusion_matrix.html (last access date: 16.07.2020)\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and it't weights. Make sure the correct path is selected!\n",
    "model = tf.keras.models.load_model(os.path.abspath('multi_epochen.model'))\n",
    "model.load_weights(os.path.abspath('multi_epochen_weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a generator composed of all validation data images\n",
    "manual_test_datagen = ImageDataGenerator(rescale = 1. / 255) \n",
    "manual_test_generator= test_datagen.flow_from_directory( \n",
    "\t\t\t\t\t\t\t\t\tvalidation_data_dir, \n",
    "\t\t\t\ttarget_size =(img_width, img_height), \n",
    "\t\tbatch_size = 500, class_mode ='categorical') \n",
    "\n",
    "test_imgs, test_labels = next(manual_test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the items of the manual_test_generator\n",
    "predictions = model.predict_generator(manual_test_generator, steps = 1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert one hot encoding into array of one integer that represents the class\n",
    "predictions = tf.argmax(predictions, axis=1)\n",
    "test_labels = tf.argmax(test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrix and define its labels\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "cm_plot_labels = ['Bauhaus', 'Expressionismus', 'Impressionismus', 'Renaissance', 'Romantik'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title=\"Confusion Matrix\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
